import asyncio
import os
import sys
import uuid
from pathlib import Path
from typing import Optional

# Configurar path para imports
sys.path.insert(0, str(Path(__file__).parent))

from dotenv import load_dotenv
import numpy as np

try:
    import sounddevice as sd
except ImportError:
    print("âš ï¸ sounddevice no instalado. Audio playback desactivado.")
    sd = None

from config.settings import Settings
from config.container import DIContainer
from app.domain.entities.conversation import Conversation
from app.domain.entities.message import Message, MessageRole
from app.ports.output.llm_port import LLMRequest
from app.ports.output.knowledge_base_port import KnowledgeBaseQuery


class HotelKioskApp:
    """
    AplicaciÃ³n principal: Kiosco Interactivo del Hotel.
    
    Modos de ejecuciÃ³n:
    - interactive: Escucha micrÃ³fono en tiempo real
    - demo: Procesa preguntas predefinidas (sin micrÃ³fono)
    """
    
    def __init__(self, settings: Settings):
        """
        Constructor.
        
        Args:
            settings: ConfiguraciÃ³n validada
        """
        self.settings = settings
        self.container = DIContainer(settings)
        self.conversation: Optional[Conversation] = None
        self.is_running = False
    
    async def initialize(self) -> None:
        """Inicializa todos los componentes"""
        await self.container.initialize()
        
        # Crear conversaciÃ³n
        self.conversation = Conversation(
            session_id=str(uuid.uuid4()),
            language="es"
        )
        
        # Inyectar conversaciÃ³n en el servicio
        assistant_service = self.container.get_assistant_service()
        assistant_service.set_conversation(self.conversation)
        
        # Cargar base de conocimiento
        await self._load_knowledge_base()
    
    async def _load_knowledge_base(self) -> None:
        """Carga documentos en la base de conocimiento"""
        kb_port = self.container.get_kb_port()
        
        # Documentos de ejemplo del hotel
        hotel_docs = [
            "El hotel dispone de recepciÃ³n 24/7. TelÃ©fono: +34-XXX-XXXX. Email: info@hotel.com",
            "Check-in a las 15:00, check-out a las 11:00. Puedes solicitar check-in anticipado o check-out tardÃ­o.",
            "Disponemos de desayuno buffet de 6:30 a 10:30 en el restaurante principal.",
            "El hotel cuenta con gimnasio, piscina climatizada, spa y zona de negocios.",
            "WiFi gratuito en todas las habitaciones. Velocidad: 100 Mbps. Red: HOTEL-WIFI, ContraseÃ±a: disponible en recepciÃ³n.",
            "Tarifas: HabitaciÃ³n individual â‚¬80/noche, doble â‚¬100/noche, suite â‚¬150/noche.",
            "Estacionamiento: â‚¬10/noche. Garaje cubierto con vigilancia 24/7.",
            "UbicaciÃ³n: Centro histÃ³rico, a 5 minutos del metro, 10 minutos del aeropuerto.",
            "Tenemos servicio de conserjerÃ­a para reservar excursiones y restaurantes.",
            "Mascotas permitidas: â‚¬15/noche adicionales. MÃ¡ximo 2 mascotas por habitaciÃ³n.",
        ]
        
        print("ðŸ“š Cargando base de conocimiento...")
        await kb_port.add_documents(
            documents=hotel_docs,
            metadata={"source": "hotel_info", "type": "static"}
        )
    
    async def run_interactive_mode(self) -> None:
        """
        Modo interactivo: captura audio del micrÃ³fono.
        
        Flujo CORREGIDO (sin eco infinito):
        1. Usuario habla â†’ VAD detecta voz
        2. Silencio â†’ DETIENE micrÃ³fono
        3. STT â†’ LLM â†’ TTS â†’ Reproduce respuesta
        4. REINICIA micrÃ³fono para siguiente pregunta
        """
        print("\nðŸŽ¤ Modo interactivo: Habla cuando estÃ©s listo, Ctrl+C para salir")
        print("=" * 60)
        
        self.is_running = True
        assistant_service = self.container.get_assistant_service()
        audio_input = self.container.get_audio_input_port()
        
        captured_audio: Optional[bytes] = None
        silence_detected = False
        
        def on_audio_chunk(chunk: bytes) -> None:
            """Callback cuando se captura audio"""
            nonlocal captured_audio
            if captured_audio is None:
                captured_audio = chunk
            else:
                captured_audio += chunk
        
        def on_silence_detected() -> None:
            """Callback cuando se detecta silencio (fin de discurso)"""
            nonlocal silence_detected
            silence_detected = True
        
        try:
            # Iniciar escucha inicial
            audio_input.start_listening(on_audio_chunk, on_silence_detected)
            
            while self.is_running:
                try:
                    # Esperar a que el usuario hable
                    await asyncio.sleep(0.1)
                    
                    # Si detectamos silencio y hay audio capturado suficiente
                    if silence_detected and captured_audio and len(captured_audio) > 1000:
                        # ============================================================
                        # CORRECCIÃ“N CRÃTICA #1: DETENER MICRÃ“FONO (Prevenir Eco)
                        # ============================================================
                        audio_input.stop_listening()
                        print("\nðŸ”„ Procesando...")
                        
                        try:
                            # Flujo completo: Audio â†’ Texto â†’ Respuesta â†’ Audio
                            response_text, response_audio = await assistant_service.process_audio(
                                captured_audio
                            )
                            
                            # Mostrar respuesta
                            print(f"\nðŸ¤– Asistente: {response_text}")
                            
                            # Reproducir audio (sin que el mic escuche)
                            if response_audio:
                                await self._play_audio(response_audio)
                            
                            # Mostrar contexto del historial
                            if self.conversation and len(self.conversation.messages) >= 2:
                                print(f"\nðŸ“‹ Historial:")
                                for msg in self.conversation.messages[-2:]:
                                    content_preview = msg.content[:80] + "..." if len(msg.content) > 80 else msg.content
                                    print(f"  {msg.role.value.upper()}: {content_preview}")
                            
                        except Exception as e:
                            print(f"âœ— Error procesando: {e}")
                        
                        finally:
                            # ========================================================
                            # CORRECCIÃ“N CRÃTICA #1.2: LIMPIAR Y REINICIAR
                            # ========================================================
                            captured_audio = None
                            silence_detected = False
                            
                            print("\nðŸŽ¤ Escuchando de nuevo...")
                            
                            # Reiniciar micrÃ³fono para siguiente pregunta
                            audio_input.start_listening(on_audio_chunk, on_silence_detected)
                        
                except KeyboardInterrupt:
                    self.is_running = False
                    break
                    
                except Exception as e:
                    print(f"âœ— Error: {e}")
                    await asyncio.sleep(1)
                    
        finally:
            audio_input.stop_listening()
            print("\nâœ“ Modo interactivo finalizado")
    
    async def run_demo_mode(self) -> None:
        """
        Modo demo: simula preguntas predefinidas.
        
        Ãštil para:
        - Testing sin micrÃ³fono
        - DemostraciÃ³n
        - Benchmarking
        """
        print("\nðŸŽ¬ Modo demo: Procesando preguntas de ejemplo")
        print("=" * 60)
        
        questions = [
            "Â¿CuÃ¡l es el horario de check-in?",
            "Â¿Hay WiFi en las habitaciones?",
            "Â¿DÃ³nde estÃ¡ ubicado el hotel?",
            "Â¿Puedo traer mi mascota?",
        ]
        
        assistant_service = self.container.get_assistant_service()
        
        for i, question in enumerate(questions, 1):
            print(f"\nðŸ“ Pregunta {i}: {question}")
            
            try:
                # Simular que viene de STT (saltamos la captura de audio)
                
                # AÃ±adir pregunta al historial
                if self.conversation:
                    self.conversation.add_message(
                        Message(question, MessageRole.USER)
                    )
                
                # Buscar contexto
                kb_port = self.container.get_kb_port()
                kb_results = await kb_port.search(
                    KnowledgeBaseQuery(query_text=question, top_k=3)
                )
                kb_context = "\n".join([r.content for r in kb_results])
                
                # Generar respuesta
                llm_port = self.container.get_llm_port()
                llm_request = LLMRequest(
                    user_message=question,
                    conversation_history=self.conversation.get_recent_context(3) if self.conversation else "",
                    hotel_context=kb_context,
                    language="es"
                )
                
                llm_response = await llm_port.generate(llm_request)
                response_text = llm_response.text
                
                # Guardar en historial
                if self.conversation:
                    self.conversation.add_message(
                        Message(response_text, MessageRole.ASSISTANT)
                    )
                
                print(f"ðŸ¤– Respuesta: {response_text}")
                print(f"â±ï¸ Latencia: {llm_response.latency_ms:.1f}ms")
                
            except Exception as e:
                print(f"âœ— Error: {e}")
            
            await asyncio.sleep(1)
        
        print("\nâœ“ Demo finalizado")
    
    async def _play_audio(self, audio_bytes: bytes) -> None:
        """
        Reproduce audio usando sounddevice.
        Soporta WAV nativo y convierte MP3/otros usando FFmpeg.
        
        Args:
            audio_bytes: Audio en formato WAV o MP3
        """
        if sd is None:
            print("âš ï¸ sounddevice no disponible, saltando reproducciÃ³n")
            return
        
        try:
            import io
            import wave
            import subprocess
            import tempfile
            
            # Intentar leer como WAV directo
            try:
                with wave.open(io.BytesIO(audio_bytes), 'rb') as wav_file:
                    frames = wav_file.readframes(wav_file.getnframes())
                    audio_data = np.frombuffer(frames, dtype=np.int16).astype(np.float32) / 32768
                    sample_rate = wav_file.getframerate()
            except wave.Error:
                # Si falla, asumir que es MP3 (ElevenLabs) y convertir con FFmpeg
                # print("â„¹ï¸ Convirtiendo formato de audio...")
                
                with tempfile.NamedTemporaryFile(suffix=".mp3", delete=False) as tmp_mp3:
                    tmp_mp3.write(audio_bytes)
                    mp3_path = tmp_mp3.name
                
                wav_path = mp3_path.replace(".mp3", ".wav")
                
                # Convertir MP3 a WAV (16kHz, 16-bit, mono)
                subprocess.run([
                    "ffmpeg", "-y", "-i", mp3_path,
                    "-ar", "16000", "-ac", "1", "-f", "wav", wav_path
                ], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, check=True)
                
                # Leer el WAV convertido
                with wave.open(wav_path, 'rb') as wav_file:
                    frames = wav_file.readframes(wav_file.getnframes())
                    audio_data = np.frombuffer(frames, dtype=np.int16).astype(np.float32) / 32768
                    sample_rate = wav_file.getframerate()
                
                # Limpiar temporales
                try:
                    os.unlink(mp3_path)
                    os.unlink(wav_path)
                except:
                    pass
            
            # Reproducir
            print("ðŸ”Š Reproduciendo respuesta...")
            sd.play(audio_data, sample_rate)
            sd.wait()
            print("âœ“ ReproducciÃ³n finalizada")
            
        except Exception as e:
            print(f"âš ï¸ No se pudo reproducir audio: {e}")


async def main():
    """Punto de entrada principal"""
    
    # Cargar variables de entorno
    load_dotenv()
    
    # Crear instancia de settings
    settings = Settings()
    
    if settings.debug:
        print("ðŸ” Modo DEBUG activado")
    
    # Crear aplicaciÃ³n
    app = HotelKioskApp(settings)
    
    try:
        # Inicializar
        await app.initialize()
        
        # Elegir modo de ejecuciÃ³n
        mode = sys.argv[1] if len(sys.argv) > 1 else "interactive"
        
        if mode == "demo":
            print("\nâœ“ Iniciando en MODO DEMO")
            await app.run_demo_mode()
        else:
            print("\nâœ“ Iniciando en MODO INTERACTIVO")
            await app.run_interactive_mode()
        
    except KeyboardInterrupt:
        print("\n\nðŸ‘‹ InterrupciÃ³n del usuario")
    
    except Exception as e:
        print(f"\nâœ— Error fatal: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    # Ejecutar
    asyncio.run(main())
